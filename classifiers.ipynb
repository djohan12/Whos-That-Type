{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries/Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 34)\n"
     ]
    }
   ],
   "source": [
    "# Reading in raw Pokemon Database.csv\n",
    "raw = pd.read_csv('Pokemon Database.csv')\n",
    "\n",
    "# Cleaning string values\n",
    "for index, pokemon in raw.iterrows():\n",
    "    for column in raw.columns:\n",
    "        if isinstance(pokemon[column], str):\n",
    "            raw.at[index, column] = pokemon[column][1:-1]\n",
    "\n",
    "# Converting Alternate Form Name to Correct Names\n",
    "raw[\"Alternate Form Name\"] = raw[\"Alternate Form Name\"].replace({\n",
    "    \"Hisui\": \"Hisuian\",\n",
    "    \"Alola\": \"Alolan\",\n",
    "    \"Galar\": \"Galarian\"\n",
    "})    \n",
    "\n",
    "# Updating Pokemon Names and Handling Missing Values\n",
    "for index, pokemon in raw.iterrows():\n",
    "    if pd.isna(pokemon['Legendary Type']):\n",
    "        raw.at[index, \"Legendary Type\"] = \"Regular\"\n",
    "    if pd.isna(pokemon[\"Secondary Type\"]):\n",
    "        raw.at[index, \"Secondary Type\"] = pokemon[\"Primary Type\"]     \n",
    "    alternate_form = pokemon['Alternate Form Name']\n",
    "    if not pd.isna(alternate_form) and isinstance(alternate_form, str):\n",
    "        if alternate_form in [\"Mega X\", \"Mega Y\"]:\n",
    "            raw.at[index, \"Pokemon Name\"] = f\"Mega {raw.at[index, 'Pokemon Name']} {alternate_form[-1]}\"\n",
    "        elif pokemon[\"Pokemon Name\"] in [\"Unown\", \"Hoopa\"]:\n",
    "            raw.at[index, \"Pokemon Name\"] = f\"{raw.at[index, 'Pokemon Name']} {alternate_form}\"\n",
    "        else:\n",
    "            raw.at[index, \"Pokemon Name\"] = f\"{alternate_form} {raw.at[index, 'Pokemon Name']}\"\n",
    "\n",
    "# Selecting Relevant Columns\n",
    "relevant = raw[['Pokemon Id', 'Pokedex Number', 'Pokemon Name',\n",
    "       'Alternate Form Name', 'Original Pokemon ID', 'Legendary Type',\n",
    "       'Pokemon Height', 'Pokemon Weight', 'Primary Type', 'Secondary Type', \n",
    "       'Male Ratio', 'Female Ratio', 'Base Happiness', 'Health Stat', 'Attack Stat',\n",
    "       'Defense Stat', 'Special Attack Stat', 'Special Defense Stat',\n",
    "       'Speed Stat', 'Base Stat Total', 'Health EV', 'Attack EV', 'Defense EV',\n",
    "       'Special Attack EV', 'Special Defense EV', 'Speed EV', 'EV Yield Total',\n",
    "       'Catch Rate', 'Experience Growth', 'Experience Growth Total', 'Egg Cycle Count']]\n",
    "\n",
    "# Remove Gigantamax Forms\n",
    "relevant = relevant.loc[relevant['Alternate Form Name'] != 'Gigantamax']\n",
    "relevant = relevant.reset_index()\n",
    "\n",
    "# Define Features for Transformation\n",
    "features = ['Legendary Type', 'Pokemon Height', 'Pokemon Weight', 'Primary Type', 'Secondary Type',\n",
    "            'Male Ratio', 'Female Ratio', 'Base Happiness', 'Health Stat', 'Attack Stat', 'Defense Stat', \n",
    "            'Special Attack Stat', 'Special Defense Stat', 'Speed Stat', 'Base Stat Total', 'Health EV', \n",
    "            'Attack EV', 'Defense EV', 'Special Attack EV', 'Special Defense EV', 'Speed EV', \n",
    "            'EV Yield Total', 'Catch Rate', 'Experience Growth', 'Experience Growth Total', 'Egg Cycle Count'] \n",
    "\n",
    "# Define Numerical Features\n",
    "numerical_features = [col for col in features if col not in ['Legendary Type', 'Experience Growth', 'Primary Type', 'Secondary Type']]\n",
    "\n",
    "# Apply Label Encoding to Typings (For Classification)\n",
    "label_encoder_primary = LabelEncoder()\n",
    "label_encoder_secondary = LabelEncoder()\n",
    "\n",
    "relevant['Primary Typing Label'] = label_encoder_primary.fit_transform(relevant['Primary Type'])\n",
    "relevant['Secondary Typing Label'] = label_encoder_secondary.fit_transform(relevant['Secondary Type'])\n",
    "\n",
    "# Define One-Hot Encoding for Categorical Features, Scaling Values\n",
    "categorical_features = ['Legendary Type', 'Experience Growth']\n",
    "transformer = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),  \n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  \n",
    "])\n",
    "\n",
    "# Apply Transformations\n",
    "transformed = transformer.fit_transform(relevant[features])\n",
    "encoded_feature_names = transformer.get_feature_names_out()\n",
    "\n",
    "# Convert to DataFrame\n",
    "processed = pd.DataFrame(transformed, columns=encoded_feature_names)\n",
    "\n",
    "# Add Primary & Secondary Typing Labels\n",
    "processed['Primary Typing Label'] = relevant['Primary Typing Label']\n",
    "processed['Secondary Typing Label'] = relevant['Secondary Typing Label']\n",
    "\n",
    "# Save Processed Data\n",
    "print(processed.shape)\n",
    "processed.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Test and Train Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Features and Labels Matricies\n",
    "X = processed.drop(columns=['Primary Typing Label', 'Secondary Typing Label'])\n",
    "y = processed[['Primary Typing Label']]\n",
    "\n",
    "# Split into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Guess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.04      0.04        26\n",
      "           1       0.13      0.12      0.13        16\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.14      0.15      0.15        13\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.06      0.14      0.09         7\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         9\n",
      "          12       0.11      0.03      0.05        32\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.07      0.05      0.06        22\n",
      "          15       0.12      0.08      0.10        24\n",
      "          16       0.06      0.09      0.07        11\n",
      "          17       0.10      0.03      0.05        31\n",
      "\n",
      "    accuracy                           0.04       270\n",
      "   macro avg       0.05      0.04      0.04       270\n",
      "weighted avg       0.06      0.04      0.05       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declari Classifier and Train\n",
    "random_guess = DummyClassifier(strategy='uniform', random_state=42)\n",
    "random_guess.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = random_guess.predict(X_test)\n",
    "\n",
    "# Accuracy Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilistic Guess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.08      0.08        26\n",
      "           1       0.08      0.06      0.07        16\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.11      0.11      0.11         9\n",
      "           6       0.07      0.08      0.07        13\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.11      0.18      0.14        17\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.14      0.11      0.12         9\n",
      "          12       0.04      0.03      0.03        32\n",
      "          13       0.10      0.09      0.10        11\n",
      "          14       0.08      0.09      0.09        22\n",
      "          15       0.00      0.00      0.00        24\n",
      "          16       0.09      0.09      0.09        11\n",
      "          17       0.12      0.13      0.12        31\n",
      "\n",
      "    accuracy                           0.07       270\n",
      "   macro avg       0.06      0.06      0.06       270\n",
      "weighted avg       0.06      0.07      0.06       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declari Classifier and Train\n",
    "prob_guess = DummyClassifier(strategy='stratified', random_state=42)\n",
    "prob_guess.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = prob_guess.predict(X_test)\n",
    "\n",
    "# Accuracy Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        26\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.36      0.56      0.43         9\n",
      "           3       0.36      0.31      0.33        13\n",
      "           4       0.89      0.67      0.76        12\n",
      "           5       0.25      0.22      0.24         9\n",
      "           6       0.43      0.23      0.30        13\n",
      "           8       0.14      0.14      0.14         7\n",
      "           9       0.21      0.35      0.27        17\n",
      "          10       0.10      0.12      0.11         8\n",
      "          11       0.00      0.00      0.00         9\n",
      "          12       0.37      0.91      0.53        32\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.59      0.45      0.51        22\n",
      "          15       0.88      0.29      0.44        24\n",
      "          16       0.60      0.55      0.57        11\n",
      "          17       0.23      0.32      0.27        31\n",
      "\n",
      "    accuracy                           0.38       270\n",
      "   macro avg       0.35      0.32      0.31       270\n",
      "weighted avg       0.39      0.38      0.35       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declare Classifier and Train\n",
    "svm_classifier = SVC(kernel='rbf', decision_function_shape='ovr')  # 'ovo' also works\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5.8575\n",
      "Epoch 10, Loss: 5.6689\n",
      "Epoch 20, Loss: 5.5055\n",
      "Epoch 30, Loss: 5.3503\n",
      "Epoch 40, Loss: 5.1991\n",
      "Epoch 50, Loss: 5.0536\n",
      "Epoch 60, Loss: 4.9167\n",
      "Epoch 70, Loss: 4.7914\n",
      "Epoch 80, Loss: 4.6785\n",
      "Epoch 90, Loss: 4.5765\n",
      "Overall Accuracy (either primary or secondary correct): 0.3630\n",
      "\n",
      "Primary Type Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.16      0.23      0.19        26\n",
      "     Class 1       0.00      0.00      0.00        16\n",
      "     Class 2       0.08      0.11      0.10         9\n",
      "     Class 3       0.13      0.38      0.20        13\n",
      "     Class 4       0.26      0.67      0.37        12\n",
      "     Class 5       0.16      0.44      0.24         9\n",
      "     Class 6       0.50      0.08      0.13        13\n",
      "     Class 8       0.00      0.00      0.00         7\n",
      "     Class 9       0.12      0.18      0.14        17\n",
      "    Class 10       0.00      0.00      0.00         8\n",
      "    Class 11       0.00      0.00      0.00         9\n",
      "    Class 12       0.43      0.59      0.50        32\n",
      "    Class 13       0.00      0.00      0.00        11\n",
      "    Class 14       0.53      0.41      0.46        22\n",
      "    Class 15       0.38      0.25      0.30        24\n",
      "    Class 16       0.38      0.45      0.42        11\n",
      "    Class 17       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.25       270\n",
      "   macro avg       0.18      0.22      0.18       270\n",
      "weighted avg       0.22      0.25      0.21       270\n",
      "\n",
      "\n",
      "Secondary Type Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.05      0.20      0.08         5\n",
      "     Class 1       0.00      0.00      0.00        11\n",
      "     Class 2       0.25      0.18      0.21        11\n",
      "     Class 3       0.14      0.08      0.10        13\n",
      "     Class 4       0.33      0.44      0.38        25\n",
      "     Class 5       0.13      0.43      0.20        14\n",
      "     Class 6       0.00      0.00      0.00        13\n",
      "     Class 7       0.26      0.38      0.31        26\n",
      "     Class 8       0.00      0.00      0.00        10\n",
      "     Class 9       0.50      0.07      0.12        14\n",
      "    Class 10       0.50      0.20      0.29        15\n",
      "    Class 11       0.00      0.00      0.00         8\n",
      "    Class 12       0.41      0.52      0.46        27\n",
      "    Class 13       0.08      0.10      0.09        10\n",
      "    Class 14       0.46      0.44      0.45        27\n",
      "    Class 15       0.05      0.12      0.07         8\n",
      "    Class 16       0.29      0.17      0.21        12\n",
      "    Class 17       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.24       270\n",
      "   macro avg       0.19      0.19      0.17       270\n",
      "weighted avg       0.24      0.24      0.22       270\n",
      "\n",
      "Final results saved to final_predictions_and_loss.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Defining Features and Labels Matricies\n",
    "X = processed.drop(columns=['Primary Typing Label', 'Secondary Typing Label'])\n",
    "y = processed[['Primary Typing Label', 'Secondary Typing Label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)  # Ensure labels are long integers for multi-class\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 18  # Since there are 18 possible types\n",
    "\n",
    "# Define two separate output layers for primary and secondary types\n",
    "layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "activation = nn.ReLU()\n",
    "primary_output = nn.Linear(hidden_dim, output_dim)\n",
    "secondary_output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "# Optimizer and loss function\n",
    "params = list(layer1.parameters()) + list(primary_output.parameters()) + list(secondary_output.parameters())\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
    "optimizer = optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    layer1.train()\n",
    "    primary_output.train()\n",
    "    secondary_output.train()\n",
    "\n",
    "    out1 = layer1(X_train_tensor)\n",
    "    act1 = activation(out1)\n",
    "\n",
    "    primary_logits = primary_output(act1)\n",
    "    secondary_logits = secondary_output(act1)\n",
    "\n",
    "    primary_loss = criterion(primary_logits, y_train_tensor[:, 0]) \n",
    "    secondary_loss = criterion(secondary_logits, y_train_tensor[:, 1]) \n",
    "\n",
    "    total_loss = primary_loss + secondary_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item():.4f}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    final_primary_logits = primary_output(layer1(X_test_tensor))\n",
    "    final_secondary_logits = secondary_output(layer1(X_test_tensor))\n",
    "\n",
    "    final_primary_preds = torch.argmax(final_primary_logits, dim=1)\n",
    "    final_secondary_preds = torch.argmax(final_secondary_logits, dim=1)\n",
    "\n",
    "    final_predictions_list = list(zip(final_primary_preds.numpy(), final_secondary_preds.numpy()))\n",
    "    final_actual_labels_list = list(zip(y_test_tensor[:, 0].numpy(), y_test_tensor[:, 1].numpy()))\n",
    "\n",
    "    final_primary_loss = criterion(final_primary_logits, y_test_tensor[:, 0])\n",
    "    final_secondary_loss = criterion(final_secondary_logits, y_test_tensor[:, 1])\n",
    "    final_total_loss = final_primary_loss + final_secondary_loss\n",
    "    \n",
    "    correct_preds = ((final_primary_preds == y_test_tensor[:, 0]) | (final_secondary_preds == y_test_tensor[:, 1])).float()\n",
    "    accuracy = correct_preds.mean()\n",
    "\n",
    "    primary_classes = torch.unique(y_test_tensor[:, 0])\n",
    "    secondary_classes = torch.unique(y_test_tensor[:, 1])\n",
    "    primary_target_names = [f'Class {i}' for i in primary_classes.numpy()]\n",
    "    secondary_target_names = [f'Class {i}' for i in secondary_classes.numpy()]\n",
    "    \n",
    "    primary_report = classification_report(y_test_tensor[:, 0].numpy(), final_primary_preds.numpy(),\n",
    "                                           target_names=primary_target_names)\n",
    "    secondary_report = classification_report(y_test_tensor[:, 1].numpy(), final_secondary_preds.numpy(),\n",
    "                                             target_names=secondary_target_names)\n",
    "\n",
    "print(f\"Overall Accuracy (either primary or secondary correct): {accuracy.item():.4f}\")\n",
    "print(\"\\nPrimary Type Classification Report:\")\n",
    "print(primary_report)\n",
    "print(\"\\nSecondary Type Classification Report:\")\n",
    "print(secondary_report)\n",
    "\n",
    "\n",
    "final_predictions_flat = [(p[0], p[1]) for p in final_predictions_list]\n",
    "final_labels_flat = [(l[0], l[1]) for l in final_actual_labels_list] \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Predictions Primary Type': [final_predictions_flat[i][0] for i in range(len(final_predictions_flat))],\n",
    "    'Actual Primary Type': [final_labels_flat[i][0] for i in range(len(final_labels_flat))],\n",
    "    'Predictions Secondary Type': [final_predictions_flat[i][1] for i in range(len(final_predictions_flat))],\n",
    "    'Actual Secondary Type': [final_labels_flat[i][1] for i in range(len(final_labels_flat))],\n",
    "    'Loss': [final_total_loss.item()] * len(final_predictions_flat)\n",
    "})\n",
    "\n",
    "results_df.to_csv('final_predictions_and_loss.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
